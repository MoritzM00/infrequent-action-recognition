{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from umap import UMAP\n",
    "\n",
    "modes = [\"train\", \"val\", \"test\"]\n",
    "embeddings: dict = {}\n",
    "samples: dict = {}\n",
    "for mode in modes:\n",
    "    embed_output: dict = torch.load(\n",
    "        f\"../outputs/embeddings/OOPS_cs_{mode}_16@7_5_Qwen3-VL-Embedding-2B_448.pt\"\n",
    "    )\n",
    "    embeddings[mode] = embed_output[\"embeddings\"]\n",
    "    samples[mode] = pd.DataFrame(embed_output[\"samples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "from hydra import compose, initialize\n",
    "\n",
    "from falldet.data.video_dataset_factory import get_video_datasets\n",
    "from falldet.schemas import InferenceConfig\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../config/\"):\n",
    "    cfg = compose(config_name=\"inference_config\")\n",
    "    cfg = InferenceConfig.model_validate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "kwargs = {\"return_individual\": True, \"size\": 448, \"seed\": None}\n",
    "cfg.dataset.vid_frame_count = 9\n",
    "for mode in modes:\n",
    "    datasets[mode] = get_video_datasets(cfg, mode=mode, **kwargs)[\"individual\"][\"OOPS_cs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[\"train\"].shape, embeddings[\"test\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(queries: torch.Tensor, corpus: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity matrix for the given embeddings.\n",
    "\n",
    "    Args:\n",
    "        queries: A tensor of shape (num_queries, embedding_dim)\n",
    "        corpus: A tensor of shape (num_corpus, embedding_dim)\n",
    "\n",
    "    Returns:\n",
    "        A tensor of shape (num_samples, num_samples) containing the cosine similarity values.\n",
    "    \"\"\"\n",
    "    # Normalize the embeddings to unit vectors\n",
    "    queries_normalized = F.normalize(queries, p=2, dim=1)\n",
    "    corpus_normalized = F.normalize(corpus, p=2, dim=1)\n",
    "    # Compute the cosine similarity matrix\n",
    "    cosine_similarity_matrix = queries_normalized @ corpus_normalized.T\n",
    "\n",
    "    return cosine_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cosine_similarity(embeddings[\"test\"], embeddings[\"train\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_k_nearest_neighbors(\n",
    "    queries: torch.Tensor, corpus: torch.Tensor, k: int\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Retrieve the top-k nearest neighbors for each query embedding based on cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        queries: A tensor of shape (num_queries, embedding_dim)\n",
    "        corpus: A tensor of shape (num_corpus, embedding_dim)\n",
    "        k: The number of nearest neighbors to retrieve for each query.\n",
    "    Returns:\n",
    "        A tensor of shape (num_queries, k) containing the indices of the top-k nearest\n",
    "        neighbors in the corpus for each query.\n",
    "        A tensor of shape (num_queries, k) containing the cosine similarity between each query and its top-k nearest neighbors.\n",
    "    \"\"\"\n",
    "    # Compute the cosine similarity matrix\n",
    "    cosine_similarity_matrix = compute_cosine_similarity(queries, corpus)\n",
    "\n",
    "    # Retrieve the top-k nearest neighbors for each query\n",
    "    top_k_similarity_scores, top_k_neighbors = torch.topk(cosine_similarity_matrix, k=k, dim=1)\n",
    "\n",
    "    return top_k_neighbors, top_k_similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nns, similarities = retrieve_top_k_nearest_neighbors(embeddings[\"test\"], embeddings[\"train\"], k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nns[0], similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from falldet.visualization import visualize_video\n",
    "\n",
    "\n",
    "def visualize_query_and_neighbors(\n",
    "    query_index: int,\n",
    "    neighbor_indices: torch.Tensor,\n",
    "    similarities: torch.Tensor,\n",
    "    query_mode: str = \"test\",\n",
    "    neighbor_mode: str = \"train\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize the query video and its top-k nearest neighbors.\n",
    "\n",
    "    Args:\n",
    "        query_index: The index of the query video in the samples DataFrame.\n",
    "        neighbor_indices: A tensor containing the indices of the top-k nearest neighbors in the corpus.\n",
    "        similarities: A tensor containing the similarity scores for each neighbor.\n",
    "        samples: A DataFrame containing the sample information, including video paths and labels.\n",
    "        num_frames: The number of frames to visualize for each video.\n",
    "    \"\"\"\n",
    "    # Get the query sample information\n",
    "    query_sample = samples[query_mode].iloc[query_index]\n",
    "    query_label = query_sample[\"label_str\"]\n",
    "\n",
    "    print(f\"Query Video (Index: {query_index}, Label: {query_label}):\")\n",
    "    visualize_video(idx=query_index, dataset=datasets[query_mode], nrow=9)\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize the nearest neighbors\n",
    "    for i, (neighbor_index, similarity) in enumerate(zip(neighbor_indices, similarities)):\n",
    "        neighbor_sample = samples[neighbor_mode].iloc[neighbor_index.item()]\n",
    "        neighbor_label = neighbor_sample[\"label_str\"]\n",
    "        print(\n",
    "            f\"Neighbor {i + 1} (Index: {neighbor_index}, Label: {neighbor_label}, Similarity: {similarity:.4f}):\"\n",
    "        )\n",
    "        visualize_video(idx=neighbor_index, dataset=datasets[neighbor_mode], nrow=9)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "visualize_query_and_neighbors(\n",
    "    query_index=idx, neighbor_indices=nns[idx], similarities=similarities[idx]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "\n",
    "def plot_2d_scatter(\n",
    "    embeddings: torch.Tensor, labels: list[str], title: str = \"UMAP 2D Projection of Embeddings\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot a 2D scatter plot of the given embeddings colored by their labels.\n",
    "\n",
    "    Args:\n",
    "        embeddings: A tensor of shape (num_samples, embedding_dim) containing the embeddings to plot.\n",
    "        labels: A list of strings of length (num_samples,) containing the labels for coloring the points.\n",
    "        title: The title of the plot.\n",
    "    \"\"\"\n",
    "    # Reduce dimensionality to 2D using UMAP\n",
    "    umap = UMAP(n_components=2)\n",
    "    proj = umap.fit_transform(embeddings.cpu().numpy())\n",
    "\n",
    "    unique_labels = sorted(set(labels))\n",
    "\n",
    "    cm = colormaps[\"tab20\"]\n",
    "    color_map = {label: cm(i / len(unique_labels)) for i, label in enumerate(unique_labels)}\n",
    "    # Create a scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    for label in unique_labels:\n",
    "        mask = labels == label\n",
    "        ax.scatter(proj[mask, 0], proj[mask, 1], c=[color_map[label]], label=label, s=40, alpha=0.8)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"UMAP 1\")\n",
    "    ax.set_ylabel(\"UMAP 2\")\n",
    "    ax.legend(title=\"Label\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_scatter(\n",
    "    embeddings[\"test\"], samples[\"test\"].label_str, title=\"UMAP Projection of Test Embeddings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_scatter(embeddings: torch.Tensor, labels: list[str], title: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot a 3D scatter plot of the given embeddings colored by their labels.\n",
    "\n",
    "    Args:\n",
    "        embeddings: A tensor of shape (num_samples, embedding_dim) containing the embeddings to plot.\n",
    "        labels: A list of strings of length (num_samples,) containing the labels for coloring the points.\n",
    "        title: The title of the plot.\n",
    "    \"\"\"\n",
    "    # Reduce dimensionality to 3D using UMAP\n",
    "    reducer_3d = UMAP(n_components=3, random_state=42, n_jobs=1)\n",
    "    proj_3d_mpl = reducer_3d.fit_transform(embeddings.numpy())\n",
    "\n",
    "    fig_3d = plt.figure(figsize=(10, 8))\n",
    "    ax_3d = fig_3d.add_subplot(111, projection=\"3d\")\n",
    "    unique_labels = sorted(set(labels))\n",
    "    cm = colormaps[\"tab20\"]\n",
    "    color_map = {\n",
    "        label_name: cm(i / len(unique_labels)) for i, label_name in enumerate(unique_labels)\n",
    "    }\n",
    "\n",
    "    for label_name in unique_labels:\n",
    "        mask_3d_mpl = labels == label_name\n",
    "        ax_3d.scatter(\n",
    "            proj_3d_mpl[mask_3d_mpl, 0],\n",
    "            proj_3d_mpl[mask_3d_mpl, 1],\n",
    "            proj_3d_mpl[mask_3d_mpl, 2],\n",
    "            c=[color_map[label_name]],\n",
    "            label=label_name,\n",
    "            s=30,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "    ax_3d.legend(title=\"Label\", bbox_to_anchor=(1.15, 1), loc=\"upper left\", fontsize=7)\n",
    "    ax_3d.set_title(\"UMAP 3D Projection of Embeddings\")\n",
    "    ax_3d.set_xlabel(\"UMAP 1\")\n",
    "    ax_3d.set_ylabel(\"UMAP 2\")\n",
    "    ax_3d.set_zlabel(\"UMAP 3\")\n",
    "    plt.tight_layout()\n",
    "    return ax_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_scatter(\n",
    "    embeddings[\"test\"], samples[\"test\"].label_str, title=\"UMAP Projection of Test Embeddings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "split = \"test\"\n",
    "\n",
    "labels = samples[split].label_str\n",
    "unique_labels = sorted(set(labels))\n",
    "embeddings_train = embeddings[split]\n",
    "\n",
    "colors = px.colors.qualitative.Dark24\n",
    "\n",
    "fig_3d_interactive = go.Figure()\n",
    "\n",
    "proj_3d = UMAP(n_components=3, random_state=42, n_jobs=1).fit_transform(\n",
    "    embeddings_train.cpu().numpy()\n",
    ")\n",
    "for i, label_name in enumerate(unique_labels):\n",
    "    mask_3d = labels == label_name\n",
    "    fig_3d_interactive.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=proj_3d[mask_3d, 0],\n",
    "            y=proj_3d[mask_3d, 1],\n",
    "            z=proj_3d[mask_3d, 2],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=5, opacity=0.8, color=colors[i % len(colors)]),\n",
    "            name=label_name,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig_3d_interactive.update_layout(\n",
    "    title=\"UMAP 3D Projection of Embeddings\",\n",
    "    scene=dict(xaxis_title=\"UMAP 1\", yaxis_title=\"UMAP 2\", zaxis_title=\"UMAP 3\"),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    legend_title=\"Label\",\n",
    ")\n",
    "fig_3d_interactive.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu129_vllm15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
