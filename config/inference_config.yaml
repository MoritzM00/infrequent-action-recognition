defaults:
  # dataset specified by experiment config
  - vllm: default
  - sampling: greedy
  - model: qwen/instruct
  - _self_
  - experiment: debug

input_size:
  # 200 token for qwen-3-vl
  height: 320
  width: 576

# Global video processing parameters
model_fps: 8.0  # Target frame rate for video sampling
num_frames: 16  # Number of frames to extract per video

# Inference settings
batch_size: 50
num_workers: 8
cot: false  # Chain of thought reasoning

# Output configuration
output_dir: "outputs"
save_predictions: true
save_metrics: true

log_videos: 5

# Inference settings
num_samples: null  # null = all samples

# Weights & Biases configuration
wandb:
  mode: online  # online, offline, or disabled
  project: "fall-detection-using-mllms"
  name:
  tags:

# Hydra configuration
hydra:
  job:
    chdir: false  # Keep working directory for inference
