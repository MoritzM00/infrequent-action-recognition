# from https://github.com/QwenLM/Qwen3-VL?tab=readme-ov-file#instruct-models

# Qwen3-VL Instruct sampling configuration
# Optimized for Qwen3-VL Instruct models (non-thinking mode)
# Suitable for structured JSON output with moderate creativity

# Temperature: Controls randomness (0 = greedy/deterministic, higher = more random)
# Range: 0.0 to 2.0 (typically 0.0-1.0 for structured output)
temperature: 0.7

# Maximum number of tokens to generate
max_tokens: 1024

# Top-k filtering: Only sample from the k most likely tokens
# Range: -1 (disabled), or positive integer (e.g., 20, 50)
top_k: 20

# Top-p (nucleus) sampling: Sample from smallest set of tokens with cumulative prob >= top_p
# Range: 0.0 to 1.0 (1.0 = disabled, lower = more focused)
top_p: 0.8

# Presence penalty: Penalizes tokens that have appeared at all (additive)
# Range: -2.0 to 2.0 (0.0 = no penalty, positive = discourage repetition)
# Note: Higher value (1.5) helps prevent repetitive JSON structures
presence_penalty: 0.0

# Frequency penalty: Penalizes tokens based on how often they've appeared (additive)
# Range: -2.0 to 2.0 (0.0 = no penalty, positive = discourage frequent tokens)
frequency_penalty: 0.0

# Repetition penalty: Multiplicative penalty for repeated tokens
# Range: 1.0 to 2.0 (1.0 = no penalty, >1.0 = penalize repetition)
repetition_penalty: 1.0

# Random seed for reproducibility (null = random seed each run)
seed: 3407

# Token IDs that trigger generation stop
stop_token_ids: null
